{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re, os\n",
    "import json,sys\n",
    "import csv\n",
    "import collections\n",
    "import itertools\n",
    "import pandas as pd\n",
    "pd.options.display.max_columns=50\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGG</th>\n",
       "      <th>AGGC</th>\n",
       "      <th>AGGCst2</th>\n",
       "      <th>AGGst2</th>\n",
       "      <th>Region</th>\n",
       "      <th>Regiony1</th>\n",
       "      <th>agi</th>\n",
       "      <th>agiin</th>\n",
       "      <th>id1</th>\n",
       "      <th>id2</th>\n",
       "      <th>n1</th>\n",
       "      <th>n1in</th>\n",
       "      <th>n2</th>\n",
       "      <th>n2in</th>\n",
       "      <th>y1_countyfips</th>\n",
       "      <th>y1_countyfipsin</th>\n",
       "      <th>y1_statefips</th>\n",
       "      <th>y1_statefipsin</th>\n",
       "      <th>y2_countyfips</th>\n",
       "      <th>y2_countyfipsin</th>\n",
       "      <th>y2_statefips</th>\n",
       "      <th>y2_statefipsin</th>\n",
       "      <th>n1_net</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>212470</td>\n",
       "      <td>225288.0</td>\n",
       "      <td>6037.0</td>\n",
       "      <td>998999.0</td>\n",
       "      <td>2428</td>\n",
       "      <td>1813.0</td>\n",
       "      <td>4236</td>\n",
       "      <td>3454.0</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>615.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>80177</td>\n",
       "      <td>58068.0</td>\n",
       "      <td>6059.0</td>\n",
       "      <td>998999.0</td>\n",
       "      <td>810</td>\n",
       "      <td>577.0</td>\n",
       "      <td>1549</td>\n",
       "      <td>1320.0</td>\n",
       "      <td>59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>233.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>155626</td>\n",
       "      <td>153217.0</td>\n",
       "      <td>6073.0</td>\n",
       "      <td>998999.0</td>\n",
       "      <td>2663</td>\n",
       "      <td>3075.0</td>\n",
       "      <td>5783</td>\n",
       "      <td>6113.0</td>\n",
       "      <td>73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-412.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>132.0</td>\n",
       "      <td>732008</td>\n",
       "      <td>561828.0</td>\n",
       "      <td>6999.0</td>\n",
       "      <td>998999.0</td>\n",
       "      <td>7028</td>\n",
       "      <td>4930.0</td>\n",
       "      <td>13879</td>\n",
       "      <td>10406.0</td>\n",
       "      <td>2153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>2940.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2044.0</td>\n",
       "      <td>3234.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>2098.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2597</td>\n",
       "      <td>2039.0</td>\n",
       "      <td>8001.0</td>\n",
       "      <td>998999.0</td>\n",
       "      <td>67</td>\n",
       "      <td>48.0</td>\n",
       "      <td>132</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     AGG  AGGC  AGGCst2  AGGst2  Region  Regiony1     agi     agiin     id1  \\\n",
       "47   NaN   NaN      NaN     0.0     NaN       4.0  212470  225288.0  6037.0   \n",
       "131  NaN   NaN      NaN     0.0     NaN       4.0   80177   58068.0  6059.0   \n",
       "208  NaN   NaN      NaN     0.0     NaN       4.0  155626  153217.0  6073.0   \n",
       "292  NaN  33.0      NaN     0.0     NaN     132.0  732008  561828.0  6999.0   \n",
       "344  NaN   NaN      NaN     0.0     NaN       4.0    2597    2039.0  8001.0   \n",
       "\n",
       "          id2    n1    n1in     n2     n2in  y1_countyfips  y1_countyfipsin  \\\n",
       "47   998999.0  2428  1813.0   4236   3454.0             37              0.0   \n",
       "131  998999.0   810   577.0   1549   1320.0             59              0.0   \n",
       "208  998999.0  2663  3075.0   5783   6113.0             73              0.0   \n",
       "292  998999.0  7028  4930.0  13879  10406.0           2153              0.0   \n",
       "344  998999.0    67    48.0    132     90.0              1              0.0   \n",
       "\n",
       "     y1_statefips  y1_statefipsin  y2_countyfips  y2_countyfipsin  \\\n",
       "47            6.0            98.0              0             37.0   \n",
       "131           6.0            98.0              0             59.0   \n",
       "208           6.0            98.0              0             73.0   \n",
       "292         198.0          2940.0              0           2044.0   \n",
       "344           8.0            98.0              0              1.0   \n",
       "\n",
       "     y2_statefips  y2_statefipsin  n1_net  \n",
       "47           98.0             6.0   615.0  \n",
       "131          98.0             6.0   233.0  \n",
       "208          98.0             6.0  -412.0  \n",
       "292        3234.0           180.0  2098.0  \n",
       "344          98.0             8.0    19.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(r\"Z:\\Shared Data\\IRS-SOI\\County-to-County-Migration\\1516migrationdata\")\n",
    "\n",
    "df2=pd.read_csv(\"countyoutflow1516.csv\")\n",
    "# add foreign inflows\n",
    "dfin=pd.read_csv(\"countyinflow1516.csv\")\n",
    "dfin=dfin[dfin.y1_statefips==98]\n",
    "df2 = df2.append(dfin).reset_index(drop=True)\n",
    "\n",
    "# State or Foreign (country) obs\n",
    "df2=df2[(df2.y2_statefips.between(1,56) & df2.y2_countyfips>0) | (df2.y2_statefips ==98) ] \n",
    "df2=df2[(df2.y1_statefips.between(1,56) & df2.y1_countyfips>0) | (df2.y1_statefips ==98)]\n",
    "# removes same county obs\n",
    "df2=df2[(df2.y1_statefips*1000+df2.y1_countyfips != df2.y2_statefips*1000+df2.y2_countyfips)  ]\n",
    "# missings were coded as -1. Remove them\n",
    "df2=df2[df2.n1>0]\n",
    "# Create state+county fips as ID.\n",
    "df2[\"id2\"]=df2.y2_statefips*1000+df2.y2_countyfips\n",
    "df2[\"id1\"]=df2.y1_statefips*1000+df2.y1_countyfips\n",
    "\n",
    "# Add the inflows to each pair. Used to create net and check in and out at the same time.\n",
    "df=df2.join(df2.set_index(['id2', 'id1']), on=['id1', 'id2'], how='left', rsuffix='in')\n",
    "df.n1in=df.n1in.fillna(0)\n",
    "\n",
    "# Find which states have little activity to group them into one other group.\n",
    "route_counts_state = df.groupby(['y1_statefips']).sum().reset_index()\n",
    "route_counts_state.loc[(route_counts_state.n1<150000) & (route_counts_state.n1in<150000) ,\"AGG\"]=1\n",
    "route_counts_state.loc[(route_counts_state.y1_statefips==98) ,\"AGG\"]=0\n",
    "#print(route_counts_state.AGG.value_counts())\n",
    "\n",
    "df=df.join(route_counts_state[['y1_statefips','AGG']].set_index(['y1_statefips']), on=['y1_statefips'], how='left', rsuffix='st1')\n",
    "df=df.join(route_counts_state[['y1_statefips','AGG']].set_index(['y1_statefips']), on=['y2_statefips'], how='left', rsuffix='st2')\n",
    "\n",
    "# Add census regions\n",
    "cenregions=pd.read_excel(r'Z:\\Shared Data\\IRS-SOI\\County-to-County-Migration\\SAS Programs\\state-geocodes-v-regions2011.xls')\n",
    "df=df.join(cenregions[['State\\n(FIPS)','Region']].set_index(['State\\n(FIPS)']), on=['y2_statefips'], how='left', rsuffix='y2')\n",
    "df=df.join(cenregions[['State\\n(FIPS)','Region']].set_index(['State\\n(FIPS)']), on=['y1_statefips'], how='left', rsuffix='y1')\n",
    "\n",
    "\n",
    "#print(\"DF HEAD:\")\n",
    "#print(df.head(10))\n",
    "\n",
    "# generate R99 and R999SS ids for the other group. When state is 99, the counties are all in one state group. (Undoing the above.)\n",
    "mask = (df.AGG==1) \n",
    "df.loc[mask,\"id1\"]=df.Regiony1*100000 + 99900 + df.y1_statefips\n",
    "df.loc[mask,\"y1_statefips\"]=df.Regiony1*100 + 99\n",
    "mask = (df.AGGst2==1) \n",
    "df.loc[mask,\"id2\"]=df.Region*100000 + 99900 + df.y2_statefips\n",
    "df.loc[mask,\"y2_statefips\"]=df.Region*100 + 99\n",
    "\n",
    "\n",
    "\n",
    "#print(pd.crosstab(df.y1_statefips,df.Regiony1))\n",
    "\n",
    "# replace ids of small counties with SS999 for other.\n",
    "route_counts_county1 = df.groupby(['id1']).sum().reset_index()\n",
    "route_counts_county2 = df.groupby(['id2']).sum().reset_index()\n",
    "route_counts_county2.rename(index=str, columns={\"id2\": \"id1\", \"n1\": \"n1in\", \"n1in\": \"n1\"})\n",
    "route_counts_county1.append(route_counts_county2)\n",
    "route_counts_county = route_counts_county1.groupby(['id1']).mean().reset_index()\n",
    "\n",
    "## add in state aggregates to define small as less than 50K or 1/10 of migration\n",
    "route_counts_county.y1_statefips=round(route_counts_county.id1/1000)\n",
    "route_counts_county=route_counts_county.join(\n",
    "    route_counts_state[['y1_statefips','n1','n1in']].set_index(['y1_statefips']),\n",
    "    on=['y1_statefips'], how='left', rsuffix='st1')\n",
    "\n",
    "# counties with migration less than min(50K , statemigration / 10) will be aggregated.\n",
    "route_counts_county['test']=50000\n",
    "route_counts_county.loc[route_counts_county.n1st1/10<50000,'test']=route_counts_county.n1st1/10\n",
    "route_counts_county['test1']=50000\n",
    "route_counts_county.loc[route_counts_county.n1inst1/10<50000,'test1']=route_counts_county.n1st1/10\n",
    "mask=(route_counts_county.n1< route_counts_county.test) & (route_counts_county.n1in<route_counts_county.test1)\n",
    "route_counts_county.loc[mask ,\"AGGC\"]=1\n",
    "#print(route_counts_county.AGGC.value_counts())\n",
    "\n",
    "df=df.join(route_counts_county[['id1','AGGC']].set_index(['id1']), on=['id1'], how='left', rsuffix='st1')\n",
    "df=df.join(route_counts_county[['id1','AGGC']].set_index(['id1']), on=['id2'], how='left', rsuffix='st2')\n",
    "\n",
    "mask = (df.AGGC==1) & (df.y1_statefips<99)\n",
    "df.loc[mask,\"id1\"]=df.y1_statefips*1000+999\n",
    "mask = (df.AGGCst2==1) & (df.y2_statefips<99) \n",
    "df.loc[mask,\"id2\"]=df.y2_statefips*1000+999\n",
    "\n",
    "#print(route_counts_county[(route_counts_county.id1==13303)])\n",
    "\n",
    "\n",
    "# Add State to County and State to State Migration\n",
    "route_counts_state = df.groupby(['y1_statefips', 'y2_statefips']).sum().reset_index()\n",
    "route_counts_state.id1=route_counts_state.y1_statefips*1000\n",
    "route_counts_state.id2=route_counts_state.y2_statefips*1000\n",
    "route_counts_state1 = df.groupby(['y1_statefips','id2']).sum().reset_index()\n",
    "route_counts_state1.id1=route_counts_state1.y1_statefips*1000\n",
    "route_counts_state2 = df.groupby(['id1', 'y2_statefips']).sum().reset_index()\n",
    "route_counts_state2.id2=route_counts_state2.y2_statefips*1000\n",
    "\n",
    "#print(route_counts_state[route_counts_state.y1_statefips==99].head())\n",
    "\n",
    "route_counts = df.groupby(['id1', 'id2']).sum().reset_index()\n",
    "route_counts = route_counts[route_counts.n1>0]\n",
    "\n",
    "route_counts=route_counts.append(route_counts_state)\n",
    "route_counts=route_counts.append(route_counts_state1)\n",
    "route_counts=route_counts.append(route_counts_state2)\n",
    "\n",
    "# replace 98000 with 998000 for better sort\n",
    "route_counts.loc[(route_counts.id1==98000) ,\"id1\"]=998000\n",
    "route_counts.loc[(route_counts.id2==98000) ,\"id2\"]=998000\n",
    "# add an artificial subgroup for foreign\n",
    "temp=route_counts[(route_counts.id1==998000)|(route_counts.id2==998000)]\n",
    "temp.loc[(temp.id1==998000) ,\"id1\"]=998999\n",
    "temp.loc[(temp.id2==998000) ,\"id2\"]=998999\n",
    "route_counts=route_counts.append(temp)\n",
    "\n",
    "# create net migration file.\n",
    "route_counts['n1_net']=route_counts.n1-route_counts.n1in\n",
    "route_counts_net=route_counts[route_counts.n1_net>0]\n",
    "\n",
    "route_counts[route_counts.id2==998999].head()\n",
    "#print(len(route_counts.index),len(df.index))\n",
    "#route_counts.tail(5)\n",
    "\n",
    "#route_counts_state.y1_statefips.value_counts()\n",
    "\n",
    "# To figure out which states to aggregate, let's see the histogram of n1 by state.\n",
    "#plt.close()\n",
    "#fig1=plt.figure(figsize=(17,10))\n",
    "#route_counts_state.hist(column='n1')\n",
    "#plt.xlabel(\"Trip_distance\",fontsize=15)\n",
    "#plt.ylabel(\"Frequency\",fontsize=15)\n",
    "#plt.xlim([0.0,40000.0])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of state aggregates are [0, 5, 12, 15, 21, 25, 29, 34, 39, 43, 47, 51, 56, 61, 68, 78, 92, 102]\n",
      "regions are: [6000, 8000, 12000, 13000, 17000, 26000, 34000, 36000, 37000, 39000, 42000, 48000, 53000, 199000, 299000, 399000, 499000, 998000]\n",
      "Indices of state aggregates are [0, 5, 12, 15, 21, 25, 29, 34, 39, 43, 47, 51, 56, 61, 68, 78, 92, 102]\n",
      "regions are: [6000, 8000, 12000, 13000, 17000, 26000, 34000, 36000, 37000, 39000, 42000, 48000, 53000, 199000, 299000, 399000, 499000, 998000]\n"
     ]
    }
   ],
   "source": [
    "measures={0: route_counts, 1: route_counts_net}\n",
    "for i in range(2):\n",
    "    measures.get(i)\n",
    "\n",
    "# Turn the bilateral observations into a matrix\n",
    "# Save the location of variables of interest\n",
    "    locid2=measures.get(i).columns.get_loc(\"id2\")\n",
    "    locid1=measures.get(i).columns.get_loc(\"id1\")\n",
    "    if i==0:\n",
    "        locn1=measures.get(i).columns.get_loc(\"n1\")\n",
    "    else:\n",
    "        locn1=measures.get(i).columns.get_loc(\"n1_net\")\n",
    "\n",
    "    grid = collections.Counter()\n",
    "\n",
    "    for index,line in measures.get(i).iterrows():\n",
    "        # clean empty names\n",
    "        line = [name for name in line]\n",
    "        #print(line)\n",
    "        # do pairwise stuff\n",
    "        if str(line[locid1])==str(line[locid2]):\n",
    "            grid[(int(line[locid1]),int(line[locid2]))] = '0'   \n",
    "        else:\n",
    "            grid[(int(line[locid1]),int(line[locid2]))] = line[locn1]\n",
    "        #grid[pair[::-1]] += 1\n",
    "\n",
    "    actors = sorted(set(pair[0] for pair in grid))\n",
    "\n",
    "    fips=[k for k in range(56)]\n",
    "    fips.extend([199,299,399,499,998])\n",
    "    regions=[]\n",
    "    for l in fips:\n",
    "        try:\n",
    "            regions.append(actors.index(l*1000))\n",
    "        except:\n",
    "            pass\n",
    "            #print(str(l),\"state not found\")\n",
    "    print(\"Indices of state aggregates are\", regions)\n",
    "    print(\"regions are:\" , [actors[k] for k in regions])\n",
    "\n",
    "\n",
    "\n",
    "    locals()[\"mat1516\"+str(i)]=[]\n",
    "    with open(\"connection_grid\"+str(i)+\".csv\", \"w\", newline=\"\") as fp:\n",
    "        writer = csv.writer(fp)\n",
    "        writer.writerow([''] + actors)\n",
    "        for actor in actors:\n",
    "            line = [actor,] + [int(grid[actor, other]) for other in actors]\n",
    "            locals()[\"mat1516\"+str(i)].append(line[1:])\n",
    "            writer.writerow(line)\n",
    "    #print('\\n'.join([''.join(['{:4},'.format(item) for item in row[0:10]]) \n",
    "    #      for row in mat1516[0:10]]))\n",
    "    #print(mat1516[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id   label1\n",
      "0  998000  Foreign\n",
      "1  998999  Foreign\n",
      "       id              label1\n",
      "0    6000                  CA\n",
      "1    6037     Los Angeles, CA\n",
      "2    6059          Orange, CA\n",
      "3    6073       San Diego, CA\n",
      "4    6999  Other Counties, CA\n",
      "5    8000                  CO\n",
      "6    8001           Adams, CO\n",
      "7    8005        Arapahoe, CO\n",
      "8    8031          Denver, CO\n",
      "9    8041         El Paso, CO\n",
      "10   8059       Jefferson, CO\n",
      "11   8999  Other Counties, CO\n",
      "12  12000                  FL\n",
      "13  12095          Orange, FL\n",
      "14  12999  Other Counties, FL\n",
      "15  13000                  GA\n",
      "16  13067            Cobb, GA\n",
      "17  13089          DeKalb, GA\n",
      "18  13121          Fulton, GA\n",
      "19  13135        Gwinnett, GA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['CA',\n",
       " 'CO',\n",
       " 'FL',\n",
       " 'GA',\n",
       " 'IL',\n",
       " 'MI',\n",
       " 'NJ',\n",
       " 'NY',\n",
       " 'NC',\n",
       " 'OH',\n",
       " 'PA',\n",
       " 'TX',\n",
       " 'WA',\n",
       " 'States in NE Region',\n",
       " 'States in Midwest Region',\n",
       " 'States in South Region',\n",
       " 'States in West Region',\n",
       " 'Foreign']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Labels\n",
    "os.chdir(r\"Z:\\Shared Data\\IRS-SOI\\County-to-County-Migration\\1516migrationdata\")\n",
    "df2=pd.read_csv(\"countyoutflow1516.csv\")\n",
    "\n",
    "## remove extra words\n",
    "df2.y2_countyname=df2.y2_countyname.str.replace(\" County\",\"\")\n",
    "df2.y2_countyname=df2.y2_countyname.str.replace(\" Non-migrants\",\"\")\n",
    "# get id to label data set\n",
    "dd=df2.groupby(['y2_statefips','y2_countyfips','y2_state','y2_countyname']).size().reset_index().rename(columns={0:'count'})\n",
    "dd['id'] = dd.y2_statefips*1000 + dd.y2_countyfips\n",
    "dd['label1'] = dd.y2_countyname + \", \" + dd.y2_state\n",
    "# generate labels for states and region+state observations\n",
    "ss=df2.groupby(['y2_statefips','y2_state']).size().reset_index().rename(columns={0:'count'})\n",
    "ss=ss[ss.y2_statefips<57]\n",
    "ss['label1'] = ss.y2_state\n",
    "for i in range(1,5):\n",
    "    locals()[\"ss\"+str(i)]=ss.copy(deep=True)\n",
    "    locals()[\"ss\"+str(i)]['id']= (i*100000)+ 99900 + locals()[\"ss\"+str(i)]['y2_statefips']\n",
    "ss['id'] = ss.y2_statefips*1000 \n",
    "# labels for other counties\n",
    "ss_other=ss.copy(deep=True)\n",
    "ss_other['id'] = ss_other.id+999\n",
    "ss_other['label1'] = \"Other Counties, \"+ss_other.label1\n",
    "# for regions\n",
    "cenreg=cenregions.drop_duplicates(subset=['Region'])\n",
    "cenreg['id']= (cenreg.Region*100+99)*1000\n",
    "cenreg['label1']=\"States in \"+ cenreg.Name.str.replace(\"Northeast\",\"NE\")\n",
    "# for foreign\n",
    "matrixF={}\n",
    "matrixF['id']=[998000,998999]\n",
    "matrixF['label1']=[\"Foreign\",\"Foreign\"]\n",
    "\n",
    "F=pd.DataFrame(matrixF)\n",
    "\n",
    "print(F.head())\n",
    "dd=dd.append(cenreg)\n",
    "dd=dd.append(ss).append(ss1).append(ss2).append(ss3).append(ss4)\n",
    "dd=dd.append(ss_other)\n",
    "dd=dd.append(F)\n",
    "\n",
    "dd = dd[['id','label1']].drop_duplicates(subset='id')\n",
    "\n",
    "#testing\n",
    "#print(df2[(df2.y2_statefips==8)&(df2.y2_countyfips==25)])\n",
    "\n",
    "actors1=pd.DataFrame(data=actors,    # values\n",
    "                   columns=['id'], dtype='int32')  # 1st row as the column names\n",
    "#print(actors1.head())\n",
    "actors2=actors1.join(dd.set_index(['id']), on=['id'], how='left')\n",
    "print(actors2.head(20))\n",
    "\n",
    "names= actors2.label1.tolist()\n",
    "migration={}\n",
    "migration={'names':names,'regions': regions,'matrix':{'2015-16':mat15160, '2015-16 (Net)':mat15161}}\n",
    "\n",
    "#test\n",
    "migration.keys()\n",
    "[migration['names'][i] for i in migration['regions']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r\"Z:\\Evaluations\\Migration\\State-County-migration-plot\\docs\")\n",
    "with open('migration.json', 'w') as outfile:\n",
    "    json.dump(migration, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
